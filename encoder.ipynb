{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RUN_EXAMPLES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "class Create_Embedding(nn.Module):\n",
    "    def __init__(self, num_embeds, vocab):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab, num_embeds)\n",
    "        self.num_embeds = num_embeds\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.embeddings(input) * math.sqrt(self.num_embeds) # the second part of the equation is 'Softmax'\n",
    "    \n",
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "embedding = Create_Embedding(512, 11)\n",
    "embedded_input = embedding(src)\n",
    "print(embedded_input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "class Layer_Norm(nn.Module):\n",
    "    def __init__(self, num_embeddings, eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(num_embeddings))            # (1, num_embeds)\n",
    "        self.beta = nn.Parameter(torch.zeros(num_embeddings))            # (1, num_embeds)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, embedded_input):\n",
    "        mean_matrix = embedded_input.mean(-1, keepdim=True)           # (batch_size, context_size, 1)\n",
    "        std_matrix = embedded_input.std(-1, keepdim=True) + self.eps  # (batch_size, context_size, 1)\n",
    "        normalization = (embedded_input - mean_matrix) / std_matrix   # (batch_size, context_size, num_embeds)\n",
    "        layer_normalization = self.gamma * normalization + self.beta  # (batch_size, context_size, num_embeds)\n",
    "        return layer_normalization\n",
    "    \n",
    "layer_norm = Layer_Norm(512)\n",
    "layer_norm_output = layer_norm.forward(embedded_input)\n",
    "print(layer_norm_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "class Multi_Headed_Attention(nn.Module):\n",
    "    def __init__(self, num_embeddings, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings \n",
    "        self.num_heads = heads\n",
    "        self.num_headings = self.num_embeddings // self.num_heads\n",
    "        self.query_linear_layer = nn.Linear(self.num_embeddings, self.num_embeddings)\n",
    "        self.key_linear_layer = nn.Linear(self.num_embeddings, self.num_embeddings)\n",
    "        self.value_linear_layer = nn.Linear(self.num_embeddings, self.num_embeddings)\n",
    "        self.output_linear_layer = nn.Linear(self.num_embeddings, self.num_embeddings)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, embedded_input):\n",
    "        \n",
    "        num_batches, _, _ = embedded_input.shape\n",
    "        \n",
    "        query = self.query_linear_layer(embedded_input)\n",
    "        key = self.query_linear_layer(embedded_input)\n",
    "        value = self.query_linear_layer(embedded_input)\n",
    "        \n",
    "        # reshaping all my matrixes accoding to the amount of heads I need\n",
    "        querys = query.view(num_batches, self.num_heads, -1, self.num_headings)     # (B, H, C, E//H)\n",
    "        keys = key.view(num_batches, self.num_heads, -1, self.num_headings)         # (B, H, C, E//H)\n",
    "        values = value.view(num_batches, self.num_heads, -1, self.num_headings)     # (B, H, C, E//H)\n",
    "        \n",
    "        # self-attention mechanism \n",
    "        attention_filter = torch.matmul(querys, keys.transpose(-2, -1))             # (B, H, C, C)\n",
    "        attention_filter = attention_filter.softmax(-1)                             # (B, H, C, C)\n",
    "        attention_filter = self.dropout(attention_filter)                           # (B, H, C, C)\n",
    "        filtered_values = torch.matmul(attention_filter, values)                    # (B, H, C, E//H)\n",
    "        \n",
    "        # concatonating the heads back together\n",
    "        output = (\n",
    "            filtered_values.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(num_batches, -1, self.num_heads * self.num_headings)\n",
    "        )\n",
    "        \n",
    "        return self.output_linear_layer(output)\n",
    "\n",
    "multi_headed_attention = Multi_Headed_Attention(512, 8)\n",
    "multi_headed_attention_output = multi_headed_attention.forward(layer_norm_output)\n",
    "print(multi_headed_attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "class Add_And_Norm(nn.Module):\n",
    "    def __init__(self, num_embeddings):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.layer_norm = Layer_Norm(self.num_embeddings)\n",
    "    \n",
    "    def forward(self, input_previous_layer, output_previous_layer):\n",
    "        residual_connection = input_previous_layer + output_previous_layer\n",
    "        return layer_norm.forward(residual_connection)\n",
    "    \n",
    "add_and_norm = Add_And_Norm(512)\n",
    "add_and_norm_output = add_and_norm(layer_norm_output, multi_headed_attention_output)\n",
    "print(add_and_norm_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "class Feed_Forward(nn.Module):\n",
    "\n",
    "    def __init__(self, num_embeddings, feed_forward_dimensions, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.feed_forward_dimensions = feed_forward_dimensions\n",
    "        self.feed_forward_1 = nn.Linear(self.num_embeddings, self.feed_forward_dimensions)\n",
    "        self.feed_forward_2 = nn.Linear(self.feed_forward_dimensions, self.num_embeddings)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, embedded_input):\n",
    "        return self.feed_forward_2(self.dropout(self.feed_forward_1(embedded_input).relu()))\n",
    "    \n",
    "feed_forward = Feed_Forward(512, 2048)\n",
    "feed_forward_output = feed_forward(add_and_norm_output)\n",
    "print(feed_forward_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(self, num_embeddings, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_norm = clones(Layer_Norm(self.num_embeddings), 4)\n",
    "        self.multi_headed_attention = Multi_Headed_Attention(num_embeddings, num_heads)\n",
    "        self.add_and_norm = clones(Add_And_Norm(self.num_embeddings), 2)\n",
    "        self.feed_forward = Feed_Forward(num_embeddings, num_heads)\n",
    "        \n",
    "    def forward(self, embedded_input):\n",
    "        tensor_1 = embedded_input\n",
    "        for i in range(self.num_layers):\n",
    "            tensor_2 = self.layer_norm[0].forward(tensor_1)\n",
    "            tensor_3 = self.multi_headed_attention.forward(tensor_2)\n",
    "            tensor_4 = self.add_and_norm[0].forward(tensor_2, tensor_3)\n",
    "            tensor_5 = self.layer_norm[1].forward(tensor_4)\n",
    "            tensor_6 = self.feed_forward.forward(tensor_5)\n",
    "            tensor_7 = self.add_and_norm[1].forward(tensor_5, tensor_6)\n",
    "            tensor_1 = self.layer_norm[2].forward(tensor_7)\n",
    "        return self.layer_norm[3].forward(tensor_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3089,  1.1938, -0.3771,  ..., -0.7220,  0.7530,  0.3284],\n",
      "         [ 0.2051,  1.4245, -1.2449,  ..., -0.5768, -0.4670,  1.0837],\n",
      "         [ 0.0998,  1.0674, -1.7092,  ...,  0.4688, -0.0969,  1.6535],\n",
      "         ...,\n",
      "         [ 0.2010,  1.1745,  0.0808,  ..., -0.3659, -0.6513,  0.0759],\n",
      "         [ 0.3338,  1.2236,  0.7162,  ...,  0.9650,  1.7414,  1.5314],\n",
      "         [ 1.1617,  0.5882, -0.9717,  ...,  0.2102, -1.9405,  0.3313]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "embedding = Create_Embedding(512, 11)\n",
    "embedded_input = embedding(src)\n",
    "encoder = Encoder(512, 8, 4)\n",
    "output = encoder.forward(embedded_input)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
